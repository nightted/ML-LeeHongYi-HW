{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW 7 - Network Pruning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17KZQg9vOAmCOPdmAFJ4RqUhWguJWwiAO",
      "authorship_tag": "ABX9TyMUdmhI8NOZj0pUE3CjQOTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nightted/ML-LeeHongYi-HW/blob/master/HW_7_Network_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sq_4CfAhmga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip\n",
        "!unzip food-11.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMYf4NJQDkuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqgyQ0SpDm0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Student-Net : MobileNet\n",
        "class StudentNet(nn.Module):\n",
        "\n",
        "  def __init__(self, b_size = 16 , width_multi = 1):\n",
        "\n",
        "    super(StudentNet,self).__init__()\n",
        "    # Define the sub_blok size\n",
        "    block_multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
        "    block_size = [b_size*size for size in block_multiplier]\n",
        "\n",
        "    #Unknown method 照做XD\n",
        "    for i in range(3,7):\n",
        "      block_size[i] = int(block_size[i]*width_multi) # width_multi as pourning ratio \n",
        "\n",
        "    self.cnn = nn.Sequential(\n",
        "        \n",
        "        # 第一個 layer 先不做 DW&PW\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(3,block_size[0],3,1,1),\n",
        "            nn.BatchNorm2d(block_size[0]),\n",
        "            nn.ReLU6(), # Relu6 限制最大輸出為6,最小輸出為0, mobile-net的Activation皆全部使用Relu6\n",
        "            nn.MaxPool2d(2,2,0)\n",
        "        )\n",
        "        ,\n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[0],block_size[0],3,1,1,groups=block_size[0]), # Depth-Wise Convlution\n",
        "            nn.BatchNorm2d(block_size[0]),\n",
        "            nn.ReLU6(),    # Relu6 限制最大輸出為6,最小輸出為0, mobile-net的Activation皆全部使用Relu6\n",
        "            nn.Conv2d(block_size[0],block_size[1],1),  # Point-Wise Convlution\n",
        "            #這邊不用再過 Relu, 經驗上 PW 完再過 Relu 效果會變差\n",
        "            nn.MaxPool2d(2,2,0) # down sampling \n",
        "        )\n",
        "        ,\n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[1],block_size[1],3,1,1,groups=block_size[1]),\n",
        "            nn.BatchNorm2d(block_size[1]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[1],block_size[2],1),           \n",
        "            nn.MaxPool2d(2,2,0)\n",
        "        )\n",
        "        ,\n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[2],block_size[2],3,1,1,groups=block_size[2]), \n",
        "            nn.BatchNorm2d(block_size[2]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[2],block_size[3],1), \n",
        "            nn.MaxPool2d(2,2,0) \n",
        "        )\n",
        "        ,\n",
        "        #這邊就不再做 down-sampling \n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[3],block_size[3],3,1,1,groups=block_size[3]), \n",
        "            nn.BatchNorm2d(block_size[3]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[3],block_size[4],1) \n",
        "        )\n",
        "        , \n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[4],block_size[4],3,1,1,groups=block_size[4]), \n",
        "            nn.BatchNorm2d(block_size[4]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[4],block_size[5],1) \n",
        "        )\n",
        "        , \n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[5],block_size[5],3,1,1,groups=block_size[5]), \n",
        "            nn.BatchNorm2d(block_size[5]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[5],block_size[6],1) \n",
        "        )\n",
        "        , \n",
        "\n",
        "        nn.Sequential(\n",
        "            nn.Conv2d(block_size[6],block_size[6],3,1,1,groups=block_size[6]), \n",
        "            nn.BatchNorm2d(block_size[6]),\n",
        "            nn.ReLU6(),    \n",
        "            nn.Conv2d(block_size[6],block_size[7],1) \n",
        "        )\n",
        "        , \n",
        "\n",
        "        # 這邊我們採用Global Average Pooling。\n",
        "        # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "        nn.AdaptiveAvgPool2d((1,1)),\n",
        "\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        #directly project to dim = 11\n",
        "        nn.Linear(block_size[7],11)\n",
        "    )\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "    out = self.cnn(x)\n",
        "    out = out.view(out.size()[0],-1)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKDb09T5Drgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-process the data\n",
        "import os \n",
        "class FoodData(Dataset):\n",
        "\n",
        "  def __init__(self,training_mode = True):\n",
        "\n",
        "    img_path = './food-11'\n",
        "    if training_mode:\n",
        "      path = os.path.join(img_path,'training')\n",
        "      #data augumentation\n",
        "      self.transform = transforms.Compose([\n",
        "                          transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.RandomRotation(15),\n",
        "                          transforms.ToTensor(),\n",
        "                                          ]) \n",
        "    else :\n",
        "      path = os.path.join(img_path,'validation')\n",
        "      self.transform = transforms.Compose([\n",
        "                          transforms.CenterCrop(256),\n",
        "                          transforms.ToTensor(),\n",
        "                                          ])\n",
        "\n",
        "    self.x_path = [ os.path.join(path,paths) for paths in sorted(os.listdir(path))]\n",
        "    self.y_label = [ paths.split('_')[0] for paths in sorted(os.listdir(path))]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    Data_X = Image.open(self.x_path[index])\n",
        "    Data_X = self.transform(Data_X)\n",
        "    Data_Y = int(self.y_label[index]) # 槓!! 每次都忘記轉 INT @@ .....\n",
        "\n",
        "    return Data_X ,Data_Y\n",
        "  \n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.x_path)\n",
        "\n",
        "def dataloader(mode , batch_size = 32):\n",
        "\n",
        "  training_mode = True if mode == 'training' else False\n",
        "  dataset = FoodData(training_mode)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset ,batch_size=batch_size ,shuffle=training_mode)\n",
        "\n",
        "  return dataloader\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuR8b8-PD7cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "865e87b7-eff4-4848-e78d-4d309f6f0293"
      },
      "source": [
        "#Download pre-train Net\n",
        "!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n",
            "To: /content/student_custom_small.bin\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 69.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duq742ZIYJRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NetPruning(student_net,new_student_net):\n",
        "  params = student_net.state_dict()\n",
        "  new_params = new_student_net.state_dict()\n",
        "\n",
        "  #Grab the idx of neuron with top gamma value\n",
        "  selected_neuron_index = []\n",
        "  for i in range(8):\n",
        "    #different layer i \n",
        "    gamma = params[\"cnn.{}.1.weight\".format(i)]\n",
        "    gamma_new = new_params[\"cnn.{}.1.weight\".format(i)]\n",
        "    len_net = len(gamma) #extract the numbers of neuron in old net\n",
        "    len_net_new = len(gamma_new )#extract the numbers of neuron in new net\n",
        "\n",
        "    priority = torch.argsort(gamma,descending=True) #Sort the neuron idx by their gamma value \n",
        "    selected_neuron_index.append(priority[:len_net_new])\n",
        "    #print(\"layer :{}\".format(i),\",original len:{}\".format(len_net),\",after shrink :{}\".format(len_net_new),\n",
        "          #\",shrink ratio:{}%\".format(int(len_net_new/len_net*100)),\",select neuron:\",priority) #Grab the top #(new_net neuron) gamma value idx of neuron  \n",
        "\n",
        "  #print(len_net,len_net_new,len_net_new/len_net*100)\n",
        "  #print(\"select neuron\",selected_neuron_index)\n",
        "\n",
        "  NOWIN_LAYER = 1 #set the current layer mark(note that it's start from the \"second\" layer.)\n",
        "  for (subnet,para) , (subnet_new,para_new) in zip(params.items(),new_params.items()):\n",
        "\n",
        "    #Only deal with the cnn layers\n",
        "    if subnet.startswith('cnn') and para.size() != torch.Size([]) and NOWIN_LAYER != len(selected_neuron_index):\n",
        "      # if is in PW layer(when encounter 3.weight), special handle for NOWIN_LAYER transform from NOWIN_LAYER -> NOWIN_LAYER+1\n",
        "      if subnet.endswith(\"3.weight\"):\n",
        "        # if is in \"LAST\" PW layer , only need to delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) \n",
        "        if len(selected_neuron_index) == NOWIN_LAYER+1:\n",
        "          new_params[subnet] = para[ : , selected_neuron_index[NOWIN_LAYER] ]\n",
        "        # if is NOT in \"LAST\" PW layer, delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) and ROW VECTOR(the deleted neuron in NOWIN_LAYER+1)\n",
        "        else:\n",
        "          new_params[subnet] = para[selected_neuron_index[NOWIN_LAYER+1] ][ : , selected_neuron_index[NOWIN_LAYER] ]\n",
        "        # After done 3.weight modification ,do layer transform from NOWIN_LAYER -> NOWIN_LAYER+1\n",
        "        NOWIN_LAYER += 1  \n",
        "\n",
        "      else:\n",
        "      # In cnn.{layer}.{0,1,2} or \"cnn.{layer}.{3}.bias\" , only need to grab the select neuron .(Or in matrix operation , only need to delete the \"ROW VECTOR\". )\n",
        "        new_params[subnet] = para[ selected_neuron_index[NOWIN_LAYER] ]\n",
        "    \n",
        "    else:\n",
        "    # In F/C layer only need to copy the whole old_net to new_net \n",
        "      new_params[subnet] = para\n",
        "\n",
        "\n",
        "  new_student_net.load_state_dict(new_params) #Remember to load the dict!!!!!\n",
        "  return new_student_net"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEh3qcZyguZT",
        "colab_type": "text"
      },
      "source": [
        "Concept of CNN multiple and Pruning :\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1fStw0OsajARGzjjOKlv7C1DBSsEDkDWr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaFOQiFERaQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the dataloader \n",
        "train_dataloader = dataloader('training', batch_size=32)\n",
        "valid_dataloader = dataloader('validation', batch_size=32)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzmoBUYnDvnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2f6b4c5-b32b-4948-a78f-db0947fd52f2"
      },
      "source": [
        "# Prepare the Net\n",
        "student_net = StudentNet().cuda()\n",
        "student_net.load_state_dict(torch.load(\"/content/student_custom_small.bin\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-4dfsiVKa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.AdamW(student_net.parameters(),lr = 0.001)\n",
        "criterion = F.cross_entropy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8jboAZRRtnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "4345dd06-2987-46eb-aa87-a4380c361fe2"
      },
      "source": [
        "def run_epoch(dataloader, update=True, alpha=0.5):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 處理 input\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "  \n",
        "        logits = student_net(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        if update:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()\n",
        "        total_num += len(inputs)\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "\n",
        "    return total_loss / total_num, total_hit / total_num\n",
        "\n",
        "now_width_mult = 1\n",
        "for i in range(5):\n",
        "    now_width_mult *= 0.95\n",
        "    new_net = StudentNet(width_multi=now_width_mult).cuda()\n",
        "    params = student_net.state_dict()\n",
        "    student_net = NetPruning(student_net, new_net)\n",
        "    now_best_acc = 0\n",
        "    for epoch in range(5):\n",
        "        student_net.train()\n",
        "        train_loss, train_acc = run_epoch(train_dataloader, update=True)\n",
        "        student_net.eval()\n",
        "        valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n",
        "        # 在每個width_mult的情況下，存下最好的model。\n",
        "        '''\n",
        "        if valid_acc > now_best_acc:\n",
        "            now_best_acc = valid_acc\n",
        "            torch.save(net.state_dict(), f'custom_small_rate_{now_width_mult}.bin')\n",
        "        '''\n",
        "        print('rate {:6.4f} epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(now_width_mult, \n",
        "            epoch, train_loss, train_acc, valid_loss, valid_acc))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rate 0.9500 epoch   0: train loss: 0.4695, acc 0.8675 valid loss: 1.1268, acc 0.8012\n",
            "rate 0.9500 epoch   1: train loss: 0.4903, acc 0.8632 valid loss: 1.1077, acc 0.8012\n",
            "rate 0.9500 epoch   2: train loss: 0.4795, acc 0.8667 valid loss: 1.1079, acc 0.7983\n",
            "rate 0.9500 epoch   3: train loss: 0.4833, acc 0.8683 valid loss: 1.1157, acc 0.7927\n",
            "rate 0.9500 epoch   4: train loss: 0.4809, acc 0.8695 valid loss: 1.1585, acc 0.7968\n",
            "rate 0.9025 epoch   0: train loss: 0.5926, acc 0.8417 valid loss: 1.1729, acc 0.7808\n",
            "rate 0.9025 epoch   1: train loss: 0.5810, acc 0.8399 valid loss: 1.1631, acc 0.7854\n",
            "rate 0.9025 epoch   2: train loss: 0.5928, acc 0.8390 valid loss: 1.1649, acc 0.7834\n",
            "rate 0.9025 epoch   3: train loss: 0.5982, acc 0.8400 valid loss: 1.2053, acc 0.7813\n",
            "rate 0.9025 epoch   4: train loss: 0.5967, acc 0.8419 valid loss: 1.1885, acc 0.7822\n",
            "rate 0.8574 epoch   0: train loss: 0.7265, acc 0.8053 valid loss: 1.2153, acc 0.7653\n",
            "rate 0.8574 epoch   1: train loss: 0.6873, acc 0.8080 valid loss: 1.2044, acc 0.7653\n",
            "rate 0.8574 epoch   2: train loss: 0.6788, acc 0.8105 valid loss: 1.2274, acc 0.7621\n",
            "rate 0.8574 epoch   3: train loss: 0.6923, acc 0.8087 valid loss: 1.2526, acc 0.7630\n",
            "rate 0.8574 epoch   4: train loss: 0.6697, acc 0.8143 valid loss: 1.2104, acc 0.7627\n",
            "rate 0.8145 epoch   0: train loss: 0.8048, acc 0.7815 valid loss: 1.2987, acc 0.7382\n",
            "rate 0.8145 epoch   1: train loss: 0.8149, acc 0.7814 valid loss: 1.2734, acc 0.7405\n",
            "rate 0.8145 epoch   2: train loss: 0.8206, acc 0.7786 valid loss: 1.2734, acc 0.7397\n",
            "rate 0.8145 epoch   3: train loss: 0.8157, acc 0.7816 valid loss: 1.3013, acc 0.7397\n",
            "rate 0.8145 epoch   4: train loss: 0.8156, acc 0.7742 valid loss: 1.3000, acc 0.7297\n",
            "rate 0.7738 epoch   0: train loss: 1.0312, acc 0.7281 valid loss: 1.4206, acc 0.7085\n",
            "rate 0.7738 epoch   1: train loss: 1.0180, acc 0.7279 valid loss: 1.3874, acc 0.7120\n",
            "rate 0.7738 epoch   2: train loss: 1.0167, acc 0.7322 valid loss: 1.4345, acc 0.7096\n",
            "rate 0.7738 epoch   3: train loss: 1.0258, acc 0.7296 valid loss: 1.4456, acc 0.7052\n",
            "rate 0.7738 epoch   4: train loss: 1.0087, acc 0.7274 valid loss: 1.4306, acc 0.7090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVhChfSqSjq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWS2ss47Sjwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHxkVVCRSj0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "776py-sGSj7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSb-qdYgSj_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8CImSCcSj4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqDJKDUq6AId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "521b7536-d280-4af9-bd8a-fc0c3f26d7c7"
      },
      "source": [
        "'''\n",
        "#Grab the idx of neuron with top gamma value\n",
        "selected_neuron_index = []\n",
        "for i in range(8):\n",
        "  #different layer i \n",
        "  gamma = params[\"cnn.{}.1.weight\".format(i)]\n",
        "  gamma_new = new_params[\"cnn.{}.1.weight\".format(i)]\n",
        "  len_net = len(gamma) #extract the numbers of neuron in old net\n",
        "  len_net_new = len(gamma_new )#extract the numbers of neuron in new net\n",
        "\n",
        "  priority = torch.argsort(gamma) #Sort the neuron idx by their gamma value \n",
        "  selected_neuron_index.append(priority[:len_net_new])\n",
        "  #print(\"layer :{}\".format(i),\",original len:{}\".format(len_net),\",after shrink :{}\".format(len_net_new),\n",
        "        #\",shrink ratio:{}%\".format(int(len_net_new/len_net*100)),\",select neuron:\",priority) #Grab the top #(new_net neuron) gamma value idx of neuron  \n",
        "\n",
        "#print(len_net,len_net_new,len_net_new/len_net*100)\n",
        "#print(\"select neuron\",selected_neuron_index)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#Grab the idx of neuron with top gamma value\\nselected_neuron_index = []\\nfor i in range(8):\\n  #different layer i \\n  gamma = params[\"cnn.{}.1.weight\".format(i)]\\n  gamma_new = new_params[\"cnn.{}.1.weight\".format(i)]\\n  len_net = len(gamma) #extract the numbers of neuron in old net\\n  len_net_new = len(gamma_new )#extract the numbers of neuron in new net\\n\\n  priority = torch.argsort(gamma) #Sort the neuron idx by their gamma value \\n  selected_neuron_index.append(priority[:len_net_new])\\n  #print(\"layer :{}\".format(i),\",original len:{}\".format(len_net),\",after shrink :{}\".format(len_net_new),\\n        #\",shrink ratio:{}%\".format(int(len_net_new/len_net*100)),\",select neuron:\",priority) #Grab the top #(new_net neuron) gamma value idx of neuron  \\n\\n#print(len_net,len_net_new,len_net_new/len_net*100)\\n#print(\"select neuron\",selected_neuron_index)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3ax9OmB-52J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "43cef2a8-3e9a-4cf4-eced-90ae0530201b"
      },
      "source": [
        "'''\n",
        "NOWIN_LAYER = 1 #set the current layer mark(note that it's start from the \"second\" layer.)\n",
        "for (subnet,para) , (subnet_new,para_new) in zip(params.items(),new_params.items()):\n",
        "\n",
        "  #Only deal with the cnn layers\n",
        "  if subnet.startswith('cnn') and para.size() != torch.Size([]) and NOWIN_LAYER != len(selected_neuron_index):\n",
        "    # if is in PW layer(when encounter 3.weight), special handle for NOWIN_LAYER transform from NOWIN_LAYER -> NOWIN_LAYER+1\n",
        "    if subnet.endswith(\"3.weight\"):\n",
        "      # if is in \"LAST\" PW layer , only need to delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) \n",
        "      if len(selected_neuron_index) == NOWIN_LAYER+1:\n",
        "        new_params[subnet] = para[ : , selected_neuron_index[NOWIN_LAYER] ]\n",
        "      # if is NOT in \"LAST\" PW layer, delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) and ROW VECTOR(the deleted neuron in NOWIN_LAYER+1)\n",
        "      else:\n",
        "        new_params[subnet] = para[selected_neuron_index[NOWIN_LAYER+1] ][ : , selected_neuron_index[NOWIN_LAYER] ]\n",
        "      # After done 3.weight modification ,do layer transform from NOWIN_LAYER -> NOWIN_LAYER+1\n",
        "      NOWIN_LAYER += 1  \n",
        "\n",
        "    else:\n",
        "    # In cnn.{layer}.{0,1,2} or \"cnn.{layer}.{3}.bias\" , only need to grab the select neuron .(Or in matrix operation , only need to delete the \"ROW VECTOR\". )\n",
        "      new_params[subnet] = para[ selected_neuron_index[NOWIN_LAYER] ]\n",
        "  \n",
        "  else:\n",
        "  # In F/C layer only need to copy the whole old_net to new_net \n",
        "    new_params[subnet] = para\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nNOWIN_LAYER = 1 #set the current layer mark(note that it\\'s start from the \"second\" layer.)\\nfor (subnet,para) , (subnet_new,para_new) in zip(params.items(),new_params.items()):\\n\\n  #Only deal with the cnn layers\\n  if subnet.startswith(\\'cnn\\') and para.size() != torch.Size([]) and NOWIN_LAYER != len(selected_neuron_index):\\n    # if is in PW layer(when encounter 3.weight), special handle for NOWIN_LAYER transform from NOWIN_LAYER -> NOWIN_LAYER+1\\n    if subnet.endswith(\"3.weight\"):\\n      # if is in \"LAST\" PW layer , only need to delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) \\n      if len(selected_neuron_index) == NOWIN_LAYER+1:\\n        new_params[subnet] = para[ : , selected_neuron_index[NOWIN_LAYER] ]\\n      # if is NOT in \"LAST\" PW layer, delete the COLUMN VECTOR(the deleted neuron in NOWIN_LAYER) and ROW VECTOR(the deleted neuron in NOWIN_LAYER+1)\\n      else:\\n        new_params[subnet] = para[selected_neuron_index[NOWIN_LAYER+1] ][ : , selected_neuron_index[NOWIN_LAYER] ]\\n      # After done 3.weight modification ,do layer transform from NOWIN_LAYER -> NOWIN_LAYER+1\\n      NOWIN_LAYER += 1  \\n\\n    else:\\n    # In cnn.{layer}.{0,1,2} or \"cnn.{layer}.{3}.bias\" , only need to grab the select neuron .(Or in matrix operation , only need to delete the \"ROW VECTOR\". )\\n      new_params[subnet] = para[ selected_neuron_index[NOWIN_LAYER] ]\\n  \\n  else:\\n  # In F/C layer only need to copy the whole old_net to new_net \\n    new_params[subnet] = para\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ya635I5XYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_params['fc.0.weight'].shape"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blKwcOp7-s-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#params['fc.0.weight'].shape"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB7b9kqbOKaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the Net paramter priority structure\n",
        "#for (subnet,para) , (subnet_new,para_new) in zip(params.items(),new_params.items()):\n",
        "#  print(subnet)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5svmyqwO5FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}